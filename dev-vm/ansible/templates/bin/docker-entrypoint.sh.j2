#!/bin/bash

run_command() {
  command_to_run=$1
  echo ""
  echo "+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+"
  echo "RUNNING: ${command_to_run}"
  echo "+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+"
  eval ${command_to_run}
  command_status=$?
  if [ ${command_status} -ne 0 ]
  then
    echo ""
    echo "ERROR!"
    echo "Command '${command_to_run}' failed with status '${command_status}'"
    echo ""
  fi
}
export -f run_command

# start ssh
run_command "service ssh start"

# start & init mysql
run_command "service mysql start"
mysql -u root -e 'CREATE DATABASE IF NOT EXISTS {{ mysql_hive_metastore_db }} DEFAULT CHARACTER SET = `latin1` DEFAULT COLLATE `latin1_swedish_ci`'
mysql -u root -e 'CREATE USER `{{ mysql_hive_metastore_user }}`@`%` IDENTIFIED BY "{{ mysql_hive_metastore_password }}"'
mysql -u root -e 'GRANT all on {{ mysql_hive_metastore_db }}.* to `{{ mysql_hive_metastore_user }}`@localhost identified by "{{ mysql_hive_metastore_password }}"'
mysql -u root -e 'flush privileges;'

# start & init hadoop
su hadoop << EOF
  export JAVA_HOME={{ java_home }}
  export HADOOP_HOME={{ hadoop_home }}
  export HADOOP_CONF_DIR={{ hadoop_conf_dir }}

  run_command "{{ hadoop_home }}/bin/hdfs namenode -format -nonInteractive"
  run_command "{{ hadoop_home }}/sbin/start-dfs.sh"
  run_command "{{ hadoop_home }}/bin/hdfs dfs -mkdir -p /user/hadoop"
  run_command "{{ hadoop_home }}/sbin/start-yarn.sh"

  run_command "{{ hadoop_home }}/bin/hdfs dfs -mkdir -p /tmp"
  run_command "{{ hadoop_home }}/bin/hdfs dfs -mkdir -p /user/hive/warehouse"
  run_command "{{ hadoop_home }}/bin/hdfs dfs -chmod g+w /tmp"
  run_command "{{ hadoop_home }}/bin/hdfs dfs -chmod g+w /user/hive/warehouse"
EOF

# init metastore schema & start the metastore interface
su hive << EOF
  export HADOOP_HOME={{ hadoop_home }}
  export HIVE_HOME={{ hive_home }}
  export HIVE_CONF_DIR={{ hive_home }}/conf
  export HADOOP_USER_CLASSPATH_FIRST=true

  run_command "{{ hive_home }}/bin/schematool -dbType mysql -initSchema"
  run_command "{{ hive_home }}/bin/hive --service metastore &"
  # export HADOOP_HOME={{ hadoop_home }}; export HADOOP_USER_CLASSPATH_FIRST=true; {{ hive_home }}/bin/hive
EOF

# start up impala
run_command "service impala-state-store start"
run_command "service impala-catalog start"
run_command "service impala-server start"

# install atscale
su atscale << EOF
  run_command "{{ atscale_unpack_dir }}/bin/install -l {{ atscale_unpack_dir }}/dev-vm-license.json  -c {{ atscale_unpack_dir }}/config.yml"
EOF

# finish up
if [[ $1 == "-daemon" ]]; then
  # hack to daemonize this script, preventing the docker container from exiting
  tail -f /dev/null
else
  # run what was passed in via docker run's COMMAND attribute
  exec "$@"
fi
